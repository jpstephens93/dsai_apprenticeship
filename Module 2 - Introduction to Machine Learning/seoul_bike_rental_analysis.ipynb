{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bike Rental in Seoul"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KATE expects your code to define variables with specific names that correspond to certain things we are interested in.\n",
    "\n",
    "KATE will run your notebook from top to bottom and check the latest value of those variables, so make sure you don't overwrite them.\n",
    "\n",
    "* Remember to uncomment the line assigning the variable to your answer and don't change the variable or function names.\n",
    "* Use copies of the original or previous DataFrames to make sure you do not overwrite them by mistake.\n",
    "\n",
    "You will find instructions below about how to define each variable.\n",
    "\n",
    "Once you're happy with your code, upload your notebook to KATE to check your feedback."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset used in this assignment was collected to help predict the demand for bike rental in Seoul at any given day and time. It can be found in the University of California Irvine [Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/Seoul+Bike+Sharing+Demand).\n",
    "\n",
    "The goal of this assignment is to preprocess the input variables into a format that makes them most useful for a linear regression model.\n",
    "\n",
    "To begin with, let's import the necessary libraries and read in the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-23T11:18:40.709123600Z",
     "start_time": "2024-01-23T11:18:40.681123800Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.rcParams[\"figure.dpi\"] = 120\n",
    "\n",
    "data = pd.read_csv(\"data/seoul_bike_data.csv\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial data inspection\n",
    "\n",
    "Now that we have the dataset loaded in, let's inspect it with the methods `.info()` and `.head()`. \n",
    "\n",
    "Note that the variable `Rented Bike Count` is the target variable we are aiming to predict in this assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-23T11:18:43.154080800Z",
     "start_time": "2024-01-23T11:18:43.123613700Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8760 entries, 0 to 8759\n",
      "Data columns (total 14 columns):\n",
      " #   Column                     Non-Null Count  Dtype  \n",
      "---  ------                     --------------  -----  \n",
      " 0   Date                       8760 non-null   object \n",
      " 1   Rented Bike Count          8760 non-null   int64  \n",
      " 2   Hour                       8760 non-null   int64  \n",
      " 3   Temperature(°C)            8760 non-null   float64\n",
      " 4   Humidity(%)                8743 non-null   object \n",
      " 5   Wind speed (m/s)           8760 non-null   float64\n",
      " 6   Visibility (10m)           8760 non-null   int64  \n",
      " 7   Dew point temperature(°C)  8760 non-null   float64\n",
      " 8   Solar Radiation (MJ/m2)    8760 non-null   float64\n",
      " 9   Rainfall(mm)               8760 non-null   float64\n",
      " 10  Snowfall (cm)              8760 non-null   float64\n",
      " 11  Seasons                    8760 non-null   object \n",
      " 12  Holiday                    8760 non-null   object \n",
      " 13  Functioning Day            8760 non-null   object \n",
      "dtypes: float64(6), int64(3), object(5)\n",
      "memory usage: 958.2+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-23T11:18:43.387329600Z",
     "start_time": "2024-01-23T11:18:43.362317100Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "          Date  Rented Bike Count  Hour  Temperature(°C) Humidity(%)  \\\n0   01/12/2017                254     0             -5.2     30%-70%   \n1   01/12/2017                204     1             -5.5     30%-70%   \n2   01/12/2017                173     2             -6.0     30%-70%   \n3   01/12/2017                107     3             -6.2     30%-70%   \n4   01/12/2017                 78     4             -6.0     30%-70%   \n5   01/12/2017                100     5             -6.4     30%-70%   \n6   01/12/2017                181     6             -6.6     30%-70%   \n7   01/12/2017                460     7             -7.4     30%-70%   \n8   01/12/2017                930     8             -7.6     30%-70%   \n9   01/12/2017                490     9             -6.5        <30%   \n10  01/12/2017                339    10             -3.5        <30%   \n11  01/12/2017                360    11             -0.5        <30%   \n12  01/12/2017                449    12              1.7        <30%   \n13  01/12/2017                451    13              2.4        <30%   \n14  01/12/2017                447    14              3.0        <30%   \n15  01/12/2017                463    15              2.1     30%-70%   \n16  01/12/2017                484    16              1.2     30%-70%   \n17  01/12/2017                555    17              0.8     30%-70%   \n18  01/12/2017                862    18              0.6     30%-70%   \n19  01/12/2017                600    19              0.0        >70%   \n20  01/12/2017                426    20             -0.3        >70%   \n21  01/12/2017                405    21             -0.8        >70%   \n22  01/12/2017                398    22             -0.9        >70%   \n23  01/12/2017                323    23             -1.3        >70%   \n24  02/12/2017                328     0             -1.8        >70%   \n\n    Wind speed (m/s)  Visibility (10m)  Dew point temperature(°C)  \\\n0                2.2              2000                      -17.6   \n1                0.8              2000                      -17.6   \n2                1.0              2000                      -17.7   \n3                0.9              2000                      -17.6   \n4                2.3              2000                      -18.6   \n5                1.5              2000                      -18.7   \n6                1.3              2000                      -19.5   \n7                0.9              2000                      -19.3   \n8                1.1              2000                      -19.8   \n9                0.5              1928                      -22.4   \n10               1.2              1996                      -21.2   \n11               1.3              1936                      -20.2   \n12               1.4              2000                      -17.2   \n13               1.6              2000                      -15.6   \n14               2.0              2000                      -14.6   \n15               3.2              2000                      -11.4   \n16               4.2               793                       -7.0   \n17               1.6              2000                       -6.5   \n18               1.4              2000                       -5.0   \n19               1.7              2000                       -3.5   \n20               1.5              1913                       -3.5   \n21               0.8              1687                       -3.6   \n22               1.5              1380                       -3.4   \n23               1.0              1265                       -3.6   \n24               1.1               994                       -3.6   \n\n    Solar Radiation (MJ/m2)  Rainfall(mm)  Snowfall (cm) Seasons     Holiday  \\\n0                      0.00           0.0            0.0  Winter  No Holiday   \n1                      0.00           0.0            0.0  Winter  No Holiday   \n2                      0.00           0.0            0.0  Winter  No Holiday   \n3                      0.00           0.0            0.0  Winter  No Holiday   \n4                      0.00           0.0            0.0  Winter  No Holiday   \n5                      0.00           0.0            0.0  Winter  No Holiday   \n6                      0.00           0.0            0.0  Winter  No Holiday   \n7                      0.00           0.0            0.0  Winter  No Holiday   \n8                      0.01           0.0            0.0  Winter  No Holiday   \n9                      0.23           0.0            0.0  Winter  No Holiday   \n10                     0.65           0.0            0.0  Winter  No Holiday   \n11                     0.94           0.0            0.0  Winter  No Holiday   \n12                     1.11           0.0            0.0  Winter  No Holiday   \n13                     1.16           0.0            0.0  Winter  No Holiday   \n14                     1.01           0.0            0.0  Winter  No Holiday   \n15                     0.54           0.0            0.0  Winter  No Holiday   \n16                     0.24           0.0            0.0  Winter  No Holiday   \n17                     0.08           0.0            0.0  Winter  No Holiday   \n18                     0.00           0.0            0.0  Winter  No Holiday   \n19                     0.00           0.0            0.0  Winter  No Holiday   \n20                     0.00           0.0            0.0  Winter  No Holiday   \n21                     0.00           0.0            0.0  Winter  No Holiday   \n22                     0.00           0.0            0.0  Winter  No Holiday   \n23                     0.00           0.0            0.0  Winter  No Holiday   \n24                     0.00           0.0            0.0  Winter  No Holiday   \n\n   Functioning Day  \n0              Yes  \n1              Yes  \n2              Yes  \n3              Yes  \n4              Yes  \n5              Yes  \n6              Yes  \n7              Yes  \n8              Yes  \n9              Yes  \n10             Yes  \n11             Yes  \n12             Yes  \n13             Yes  \n14             Yes  \n15             Yes  \n16             Yes  \n17             Yes  \n18             Yes  \n19             Yes  \n20             Yes  \n21             Yes  \n22             Yes  \n23             Yes  \n24             Yes  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Date</th>\n      <th>Rented Bike Count</th>\n      <th>Hour</th>\n      <th>Temperature(°C)</th>\n      <th>Humidity(%)</th>\n      <th>Wind speed (m/s)</th>\n      <th>Visibility (10m)</th>\n      <th>Dew point temperature(°C)</th>\n      <th>Solar Radiation (MJ/m2)</th>\n      <th>Rainfall(mm)</th>\n      <th>Snowfall (cm)</th>\n      <th>Seasons</th>\n      <th>Holiday</th>\n      <th>Functioning Day</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>01/12/2017</td>\n      <td>254</td>\n      <td>0</td>\n      <td>-5.2</td>\n      <td>30%-70%</td>\n      <td>2.2</td>\n      <td>2000</td>\n      <td>-17.6</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>Winter</td>\n      <td>No Holiday</td>\n      <td>Yes</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>01/12/2017</td>\n      <td>204</td>\n      <td>1</td>\n      <td>-5.5</td>\n      <td>30%-70%</td>\n      <td>0.8</td>\n      <td>2000</td>\n      <td>-17.6</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>Winter</td>\n      <td>No Holiday</td>\n      <td>Yes</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>01/12/2017</td>\n      <td>173</td>\n      <td>2</td>\n      <td>-6.0</td>\n      <td>30%-70%</td>\n      <td>1.0</td>\n      <td>2000</td>\n      <td>-17.7</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>Winter</td>\n      <td>No Holiday</td>\n      <td>Yes</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>01/12/2017</td>\n      <td>107</td>\n      <td>3</td>\n      <td>-6.2</td>\n      <td>30%-70%</td>\n      <td>0.9</td>\n      <td>2000</td>\n      <td>-17.6</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>Winter</td>\n      <td>No Holiday</td>\n      <td>Yes</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>01/12/2017</td>\n      <td>78</td>\n      <td>4</td>\n      <td>-6.0</td>\n      <td>30%-70%</td>\n      <td>2.3</td>\n      <td>2000</td>\n      <td>-18.6</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>Winter</td>\n      <td>No Holiday</td>\n      <td>Yes</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>01/12/2017</td>\n      <td>100</td>\n      <td>5</td>\n      <td>-6.4</td>\n      <td>30%-70%</td>\n      <td>1.5</td>\n      <td>2000</td>\n      <td>-18.7</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>Winter</td>\n      <td>No Holiday</td>\n      <td>Yes</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>01/12/2017</td>\n      <td>181</td>\n      <td>6</td>\n      <td>-6.6</td>\n      <td>30%-70%</td>\n      <td>1.3</td>\n      <td>2000</td>\n      <td>-19.5</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>Winter</td>\n      <td>No Holiday</td>\n      <td>Yes</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>01/12/2017</td>\n      <td>460</td>\n      <td>7</td>\n      <td>-7.4</td>\n      <td>30%-70%</td>\n      <td>0.9</td>\n      <td>2000</td>\n      <td>-19.3</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>Winter</td>\n      <td>No Holiday</td>\n      <td>Yes</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>01/12/2017</td>\n      <td>930</td>\n      <td>8</td>\n      <td>-7.6</td>\n      <td>30%-70%</td>\n      <td>1.1</td>\n      <td>2000</td>\n      <td>-19.8</td>\n      <td>0.01</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>Winter</td>\n      <td>No Holiday</td>\n      <td>Yes</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>01/12/2017</td>\n      <td>490</td>\n      <td>9</td>\n      <td>-6.5</td>\n      <td>&lt;30%</td>\n      <td>0.5</td>\n      <td>1928</td>\n      <td>-22.4</td>\n      <td>0.23</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>Winter</td>\n      <td>No Holiday</td>\n      <td>Yes</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>01/12/2017</td>\n      <td>339</td>\n      <td>10</td>\n      <td>-3.5</td>\n      <td>&lt;30%</td>\n      <td>1.2</td>\n      <td>1996</td>\n      <td>-21.2</td>\n      <td>0.65</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>Winter</td>\n      <td>No Holiday</td>\n      <td>Yes</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>01/12/2017</td>\n      <td>360</td>\n      <td>11</td>\n      <td>-0.5</td>\n      <td>&lt;30%</td>\n      <td>1.3</td>\n      <td>1936</td>\n      <td>-20.2</td>\n      <td>0.94</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>Winter</td>\n      <td>No Holiday</td>\n      <td>Yes</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>01/12/2017</td>\n      <td>449</td>\n      <td>12</td>\n      <td>1.7</td>\n      <td>&lt;30%</td>\n      <td>1.4</td>\n      <td>2000</td>\n      <td>-17.2</td>\n      <td>1.11</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>Winter</td>\n      <td>No Holiday</td>\n      <td>Yes</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>01/12/2017</td>\n      <td>451</td>\n      <td>13</td>\n      <td>2.4</td>\n      <td>&lt;30%</td>\n      <td>1.6</td>\n      <td>2000</td>\n      <td>-15.6</td>\n      <td>1.16</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>Winter</td>\n      <td>No Holiday</td>\n      <td>Yes</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>01/12/2017</td>\n      <td>447</td>\n      <td>14</td>\n      <td>3.0</td>\n      <td>&lt;30%</td>\n      <td>2.0</td>\n      <td>2000</td>\n      <td>-14.6</td>\n      <td>1.01</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>Winter</td>\n      <td>No Holiday</td>\n      <td>Yes</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>01/12/2017</td>\n      <td>463</td>\n      <td>15</td>\n      <td>2.1</td>\n      <td>30%-70%</td>\n      <td>3.2</td>\n      <td>2000</td>\n      <td>-11.4</td>\n      <td>0.54</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>Winter</td>\n      <td>No Holiday</td>\n      <td>Yes</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>01/12/2017</td>\n      <td>484</td>\n      <td>16</td>\n      <td>1.2</td>\n      <td>30%-70%</td>\n      <td>4.2</td>\n      <td>793</td>\n      <td>-7.0</td>\n      <td>0.24</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>Winter</td>\n      <td>No Holiday</td>\n      <td>Yes</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>01/12/2017</td>\n      <td>555</td>\n      <td>17</td>\n      <td>0.8</td>\n      <td>30%-70%</td>\n      <td>1.6</td>\n      <td>2000</td>\n      <td>-6.5</td>\n      <td>0.08</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>Winter</td>\n      <td>No Holiday</td>\n      <td>Yes</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>01/12/2017</td>\n      <td>862</td>\n      <td>18</td>\n      <td>0.6</td>\n      <td>30%-70%</td>\n      <td>1.4</td>\n      <td>2000</td>\n      <td>-5.0</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>Winter</td>\n      <td>No Holiday</td>\n      <td>Yes</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>01/12/2017</td>\n      <td>600</td>\n      <td>19</td>\n      <td>0.0</td>\n      <td>&gt;70%</td>\n      <td>1.7</td>\n      <td>2000</td>\n      <td>-3.5</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>Winter</td>\n      <td>No Holiday</td>\n      <td>Yes</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>01/12/2017</td>\n      <td>426</td>\n      <td>20</td>\n      <td>-0.3</td>\n      <td>&gt;70%</td>\n      <td>1.5</td>\n      <td>1913</td>\n      <td>-3.5</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>Winter</td>\n      <td>No Holiday</td>\n      <td>Yes</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>01/12/2017</td>\n      <td>405</td>\n      <td>21</td>\n      <td>-0.8</td>\n      <td>&gt;70%</td>\n      <td>0.8</td>\n      <td>1687</td>\n      <td>-3.6</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>Winter</td>\n      <td>No Holiday</td>\n      <td>Yes</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>01/12/2017</td>\n      <td>398</td>\n      <td>22</td>\n      <td>-0.9</td>\n      <td>&gt;70%</td>\n      <td>1.5</td>\n      <td>1380</td>\n      <td>-3.4</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>Winter</td>\n      <td>No Holiday</td>\n      <td>Yes</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>01/12/2017</td>\n      <td>323</td>\n      <td>23</td>\n      <td>-1.3</td>\n      <td>&gt;70%</td>\n      <td>1.0</td>\n      <td>1265</td>\n      <td>-3.6</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>Winter</td>\n      <td>No Holiday</td>\n      <td>Yes</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>02/12/2017</td>\n      <td>328</td>\n      <td>0</td>\n      <td>-1.8</td>\n      <td>&gt;70%</td>\n      <td>1.1</td>\n      <td>994</td>\n      <td>-3.6</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>Winter</td>\n      <td>No Holiday</td>\n      <td>Yes</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, there are a lot of different variables which take very different ranges, very different units, and, accordingly, have very different interpretations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical vs. Continuous Variables\n",
    "\n",
    "We must analyse each variable and decide how to preprocess it. Some variables are given in a discrete format, but it makes sense to make them continuous, and vice-versa. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q1. Which variable columns are continuous quantities and which are categorical?**\n",
    "\n",
    "\n",
    "Create two lists, `categorical` and `continuous` which contain the column indices for the categorical and continuous fields, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical = [0, 2, 4, 11, 12, 13]\n",
    "continuous = [1, 3, 5, 6, 7, 8, 9, 10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q2. Transform the `Date` variable to a continuous value.**\n",
    "\n",
    "\n",
    "The `Date` variable could be informative about a trend over time, and can be interpreted as a continuous variable for time. \n",
    "\n",
    "Using `.copy()`, create a copy of `data` called `data_date`. \n",
    "\n",
    "From `data_date`, create a new variable containing the values of the `Date` column, but converted to a datetime format (using `pd.to_datetime`). Be sure to specify `format=\"%d/%m/%Y\"` otherwise `pandas` may incorrectly parse the dates.\n",
    "\n",
    "Next, compute **the number of days** between each of these dates and the reference date `01/01/2017` and assign this to a new column in `data_date` called `DayCount`.\n",
    "\n",
    "\n",
    "Leave the `Date` column unchanged.\n",
    "\n",
    "*Hint: use the `pd.to_datetime()` function and subtract the values in the `Date` column from the reference date.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-31T18:12:34.751758700Z",
     "start_time": "2024-01-31T18:12:33.767379300Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[1], line 4\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mdatetime\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m datetime\n\u001B[0;32m      3\u001B[0m \u001B[38;5;66;03m# Add your code below\u001B[39;00m\n\u001B[1;32m----> 4\u001B[0m data_date \u001B[38;5;241m=\u001B[39m \u001B[43mdata\u001B[49m\u001B[38;5;241m.\u001B[39mcopy()\n\u001B[0;32m      6\u001B[0m date_converted \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mto_datetime(data_date[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mDate\u001B[39m\u001B[38;5;124m'\u001B[39m], \u001B[38;5;28mformat\u001B[39m\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m%d\u001B[39;00m\u001B[38;5;124m/\u001B[39m\u001B[38;5;124m%\u001B[39m\u001B[38;5;124mm/\u001B[39m\u001B[38;5;124m%\u001B[39m\u001B[38;5;124mY\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m      7\u001B[0m ref_date \u001B[38;5;241m=\u001B[39m datetime(\u001B[38;5;241m2017\u001B[39m, \u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m1\u001B[39m)\n",
      "\u001B[1;31mNameError\u001B[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# Add your code below\n",
    "data_date = data.copy()\n",
    "\n",
    "date_converted = pd.to_datetime(data_date['Date'], format=\"%d/%m/%Y\")\n",
    "ref_date = datetime(2017, 1, 1)\n",
    "\n",
    "day_count = []\n",
    "for dte in date_converted:\n",
    "    # dte = date_converted[0]\n",
    "    day_count.append((dte - ref_date).days)\n",
    "\n",
    "data_date['DayCount'] = day_count\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q3. Create a new DataFrame with the one-hot representation of the season**\n",
    "\n",
    "\n",
    "Categorical variables must be formatted to a one-hot representation to be ready for a linear regression model. Create $4$ new columns with the one-hot representation of the Seasons (`Spring`, `Summer`, `Autumn`, and `Winter`, in this order.)\n",
    "\n",
    "Before starting, create a copy of `data_date` called `data_season` using the `.copy()` method.\n",
    "\n",
    "*Hint: for each new column we will have rows with values `True` or `False`. To get these values, you can compare the value of the `Seasons` column to that of the new column of interest.*\n",
    "\n",
    "*In other words the new columns will look like:*\n",
    "\n",
    "...|Seasons|...|Spring|Summer|Autumn|Winter\n",
    "---|---|---|---|---|---|---\n",
    "...|Autumn|...|False|False|True|False\n",
    "...|Spring|...|True|False|False|False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_season = data_date.copy()\n",
    "\n",
    "data_season[\"Spring\"] = data_season['Seasons'].str.contains('Spring')\n",
    "data_season[\"Summer\"] = data_season['Seasons'].str.contains('Summer')\n",
    "data_season[\"Winter\"] = data_season['Seasons'].str.contains('Winter')\n",
    "data_season[\"Autumn\"] = data_season['Seasons'].str.contains('Autumn')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you have implemented the above, uncomment and run the cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_season.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q4. Transform the categorical `Humidity(%)` variable into a continuous quantity.**\n",
    "\n",
    "\n",
    "In some cases variables are given as discrete categories, but are representing ranges of a continuous values, for example the variable `Humidity(%)`.\n",
    "\n",
    "Using `.copy()`, create a copy of `data_season` called `data_humidity`. \n",
    "\n",
    "Transform the variable `Humidity(%)` to a continuous quantity. Use the mean value of each category as its continuous value (e.g. if a category is \"10%-20%\", replace it with 15).\n",
    "\n",
    "If the value of the category is \">70%\", use 85 as its mean value. Similarly, if it is \"<30%\", use 15 as its mean value.\n",
    "\n",
    "Keep the same column name.\n",
    "\n",
    "*Hint: You may want to use the `df.replace()` method.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_humidity = data_season.copy()\n",
    "\n",
    "data_humidity.replace(\n",
    "    {'30%-70%': sum([30, 70]) / 2, '<30%': sum([0, 30]) / 2, '>70%': sum([70, 100]) / 2}, inplace=True\n",
    ")\n",
    "data_humidity[\"Humidity(%)\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you have implemented `data_humidity`, uncomment and run the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_humidity[\"Humidity(%)\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us inspect the distribution of the continuous variables.\n",
    "\n",
    "Use the method `.describe()` to produce some basic statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q5. Visualize the distribution of continuous variables.**\n",
    "\n",
    "\n",
    "Inspect the histograms of the continuous variables in our data using the `.hist()` method. Assign the plot to a variable called `continuous_fig`.\n",
    "\n",
    "Note that since we have only been altering categorical variables so far, you should use the original `data` DataFrame in this question.\n",
    "\n",
    "*Hint: use the method `plt.tight_layout()` after calling `.hist()` to create a better arrangement of subplots.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create a new figure to make other figures in the notebook don't get modified\n",
    "plt.figure()\n",
    "\n",
    "# Add your code below\n",
    "cont_cols = data.describe().columns.tolist()\n",
    "\n",
    "continuous_fig = data.hist(cont_cols)\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q6. Convert continuous variables into categorical variables.**\n",
    "\n",
    "\n",
    "Note that in the histograms above, these continuous variables have very distinct distribution profiles. For instance, some variables have a very high frequency for a specific value (e.g. zero Solar Radiation). \n",
    "\n",
    "It might be useful to have such distinctive values as additional categorical variables.\n",
    "\n",
    "Create a new DataFrame with four additional columns with the binary variables for values that occur particularly often in the variables `Solar Radiation`, `Snowfall`, `Rainfall` and `Visibility`. \n",
    "Create the new columns called `Zero Solar Radiation`, `Zero Snowfall`, `Zero Rainfall` and `Max Visibility`, in this order. \n",
    "\n",
    "For instance, the binary variable `Zero Solar Radiation` will indicate if `Solar Radiation` is _close to_ zero (in this question, if it is smaller than 0.1). The same is true for columns `Zero Snowfall` and `Zero Rainfall`.\n",
    "\n",
    "Since the most common `Visibility` value is not zero, the binary variable `Max Visibility` will indicate if `Visibility` is _close to_ its maximum value (i.e. if its value is greater than its max value - 0.1).\n",
    "\n",
    "First, however, create a copy of `data_humidity` using the `.copy()` method. Call your new DataFrame `data_binary`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_binary = data_humidity.copy()\n",
    "\n",
    "data_binary[\"Zero Solar Radiation\"] = [True if x < 0.1 else False for x in data_binary[\"Solar Radiation (MJ/m2)\"]]\n",
    "data_binary[\"Zero Snowfall\"] = [True if x < 0.1 else False for x in data_binary[\"Snowfall (cm)\"]]\n",
    "data_binary[\"Zero Rainfall\"] = [True if x < 0.1 else False for x in data_binary[\"Rainfall(mm)\"]]\n",
    "data_binary[\"Max Visibility\"] = [True if x < 0.1 else False for x in data_binary[\"Solar Radiation (MJ/m2)\"]]\n",
    "\n",
    "data_binary[\"Zero Solar Radiation\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you have created these new columns, uncomment and run the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_binary[\"Zero Solar Radiation\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q7. Normalise variables.**\n",
    "\n",
    "\n",
    "It is important to ensure that input data are all scaled to the same range. Without this, the model may produce inaccurate predictions. Normalising each input variable can help train the model, allow easier interpretation of the learned parameters, and offer better regularisation.\n",
    "\n",
    "Normalise each of the continuous variables in `data` to a *z-scored* DataFrame (such that each column has zero mean and unit variance). Use the transformation:\n",
    "\n",
    "$$z = \\frac{x - \\mu}{\\sigma}$$\n",
    "\n",
    "Where `x` is the original column values, `μ` is the mean of the column, and `σ` is the standard deviation of the column.\n",
    "\n",
    "Save the results in a different DataFrame, `data_z`, and visualise the new distributions using the `.hist()` and `plt.tight_layout()` methods.\n",
    "\n",
    "Assign the plot to a variable called `normalise_fig`.\n",
    "\n",
    "*Hint: use the `mean()` and `std()` methods for the chosen columns.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create a new figure to make other figures in the notebook don't get modified\n",
    "plt.figure()\n",
    "\n",
    "# Add your code below\n",
    "data_z = (data[cont_cols] - data[cont_cols].mean()) / data[cont_cols].std()\n",
    "\n",
    "normalise_fig = data_z.hist()\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced discretisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q8. Discretising a circular variable.**\n",
    "\n",
    "\n",
    "Some continuous variables are not actually linear variables, and are not a natural input to a linear model. For example, `Hour` is a circular variable - the values 23 and 1 are actually close together in the day. \n",
    "\n",
    "Let us transform `Hour` into discrete categories.  Divide the variable into 5 categories: `Morning` (6-10), `Afternoon` (11-16), `Evening` (17-19), `Night` (20-23), `Early Morning` (0-5).\n",
    "\n",
    "For example:\n",
    "\n",
    "...|Hour|...|Morning|Afternoon|Evening|Night|Early Morning\n",
    "---|---|---|---|---|---|---|---\n",
    "...|1|...|False|False|False|False|True\n",
    "...|13|...|False|True|False|False|False\n",
    "\n",
    "\n",
    "First, however, create a copy of `data_binary` using the `.copy()` method. Call your new DataFrame `data_time_categories`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_time_categories = data_binary.copy()\n",
    "\n",
    "data_time_categories[\"Morning\"] = (data_time_categories['Hour'] >= 6) & (data_time_categories['Hour'] <= 10)\n",
    "data_time_categories[\"Afternoon\"] = (data_time_categories['Hour'] >= 11) & (data_time_categories['Hour'] <= 16)\n",
    "data_time_categories[\"Evening\"] = (data_time_categories['Hour'] >= 17) & (data_time_categories['Hour'] <= 19)\n",
    "data_time_categories[\"Night\"] = (data_time_categories['Hour'] >= 20) & (data_time_categories['Hour'] <= 23)\n",
    "data_time_categories[\"Early Morning\"] = (data_time_categories['Hour'] >= 0) & (data_time_categories['Hour'] <= 5)\n",
    "\n",
    "data_time_categories[\"Morning\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you have implemented the above question, uncomment and run the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_time_categories[\"Morning\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q9. Inspecting target variable dependency.**\n",
    "\n",
    "\n",
    "The categories chosen above for `Hour` were rather arbitrary. One more advanced data preprocessing step is to inspect how a given input variable influences the target variable. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use the `seaborn` library to plot this dependency in detail - how the target variable `Rented Bike Count` depends on `Hour` - with the `sns.violinplot()` method. It shows the distribution of bike rentals for each hour of the day. Assign the output of the plot to a variable called `bike_hour_dependency`. For input data, use the `data` DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# We create a new figure to make other figures in the notebook don't get modified\n",
    "plt.figure()\n",
    "\n",
    "# Add your code below\n",
    "bike_hour_dependency = sns.violinplot(data, x='Hour', y='Rented Bike Count')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that there is complex relation between the variables. Note that as linear models are only sensitive to the mean correlation between variables (not the full distribution), we can focus on the mean values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q10. Calculate the mean `Rented Bike Count` for each hour of the day.**\n",
    "\n",
    "\n",
    "Use the methods `.groupby()` and `.mean()` on the `data` DataFrame, save the result to a variable called `mean_count`, and plot the result using `.plot()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add your code below\n",
    "mean_count = data[['Hour', 'Rented Bike Count']].groupby('Hour').mean()\n",
    "mean_count.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q11. Discretise nonlinear dependency.**\n",
    "\n",
    "\n",
    "We see in the plot above, a highly nonlinear effect of the variable `Hour` on the mean of the target variable `Rented Bike Count`. A linear model is not sensitive to this and it is a strong indication that discretisation of the variable will help. As above, let's create categorical variables for different ranges of `Hour`, but now taking into account the dependency of the target variable.\n",
    "\n",
    "We expect that a category will be more predictive if the target does not vary too much for samples of that category. For instance, the target value is similar for the hours 10, 11, 12 and 13, indicating that the range `10 <= Hour < 14` might have good predictive power for the target.\n",
    "\n",
    "Divide `Hour` into five new columns as follows:\n",
    "\n",
    "New column name | Data\n",
    "---|---\n",
    "Hour Cat 1 | `3 <= Hour < 7`\n",
    "Hour Cat 2 | `7 <= Hour < 10`\n",
    "Hour Cat 3 | `10 <= Hour < 14`\n",
    "Hour Cat 4 | `14 <= Hour < 22`\n",
    "Hour Cat 5 | `22 <= Hour` or `Hour < 3`\n",
    " \n",
    "Which will look like:\n",
    "\n",
    "...|Hour|...|Hour Cat 1|Hour Cat 2|Hour Cat 3|Hour Cat 4|Hour Cat 5\n",
    "---|---|---|---|---|---|---|---\n",
    "...|2|...|False|False|False|False|True\n",
    "...|9|...|False|True|False|False|False\n",
    "\n",
    "First, create a copy of `data_time_categories` using the `.copy()` method. Call your new DataFrame `final_data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add your code below\n",
    "final_data = data_time_categories.copy()\n",
    "\n",
    "final_data[\"Hour Cat 1\"] = (3 <= final_data['Hour']) & (final_data['Hour'] < 7)\n",
    "final_data[\"Hour Cat 2\"] = (7 <= final_data['Hour']) & (final_data['Hour'] < 10)\n",
    "final_data[\"Hour Cat 3\"] = (10 <= final_data['Hour']) & (final_data['Hour'] < 14)\n",
    "final_data[\"Hour Cat 4\"] = (14 <= final_data['Hour']) & (final_data['Hour'] < 22)\n",
    "final_data[\"Hour Cat 5\"] = final_data['Hour'] < 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that in this case an hour-by-hour division may even be reasonable. But on the other hand, too many input variables can lead to overfitting problems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q12. Implement linear regression model.**\n",
    "\n",
    "\n",
    "Create a function with a single argument `cols`, which takes as input a `list` of column names to be used to train the model.\n",
    "\n",
    "You will need to assign these columns of the `final_data` DataFrame to a variable (`X`), assign the `Rented Bike Count` column to another variable (`Y`), and then use the `.fit()` method of the `LinearRegression` class to train your model.\n",
    "\n",
    "Note that you will have to reshape your `Y` variable using the `.reshape()` method. It is currently an array (`[254, 204, ...]`) but the `LinearRegression` model expects it as an _array of arrays_ (`[[254], [204], ...]`).\n",
    "\n",
    "Finally, use the `mean_squared_error` to compute the error. Once computed, return the error as a `float`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "# Add your code below\n",
    "# def prediction_error(cols):\n",
    "#     ...\n",
    "#     return error\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uncomment and run the code below to check your implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction_error([\"Temperature(°C)\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q13. Compare performance of different `Hour` representations.**\n",
    "\n",
    "\n",
    "Compare the predictions of our linear model on the original `Hour` variable versus our hand-crafted categorical representations (`Hour Cat 1`, `Hour Cat 2` etc).\n",
    "\n",
    "Assign the output of the `prediction_error()` function to two variables:\n",
    "  1. `model1`: for just the `Hour` variable.\n",
    "  2. `model2`: for the categorical representations that we created.\n",
    "\n",
    "Which model has the better performance? Note that with `mean_squared_error`, a lower error indicates a better fit to the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add your code below\n",
    "# model1 = ...\n",
    "# model2 = ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q14. Compare the prediction error based on the original variables to the prediction error for variables after preprocessing.**\n",
    "\n",
    "1. Save to the variable `full_model_original`, the result of calling `prediction_error()` on the original columns which are suitable for a linear regression model. In this case these are `['Hour', 'Temperature(°C)', 'Wind speed (m/s)', 'Visibility (10m)', 'Dew point temperature(°C)', 'Solar Radiation (MJ/m2)', 'Rainfall(mm)', 'Snowfall (cm)']`.\n",
    "<br><br>\n",
    "2. Save to the variable `full_model_updated`, the result of calling `prediction_error()` using our processed variables. For `full_model_updated`, include the variables from `full_model_original` that we didn't preprocess (like `Temperature(°C)`, `Wind speed (m/s)` etc), but where we have processed a variable (like `Hour`), don't include the unprocessed variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add your code below\n",
    "# full_model_original = ...\n",
    "# full_model_updated = ...\n",
    "# print(full_model_original, full_model_updated)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
